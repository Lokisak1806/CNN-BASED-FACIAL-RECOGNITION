# general functions
import os
import cv2
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from collections import OrderedDict
# visualization
from PIL import Image

# identifying faces
%pip install  mtcnn
from mtcnn.mtcnn import MTCNN
# visualizing bounding boxes
import matplotlib.patches as patches
# CNN
import keras
from sklearn.model_selection import train_test_split
# Moving files between directories
import shutil
from shutil import unpack_archive
from subprocess import check_output

dataset_path = "/kaggle/input/the-orl-database-for-training-and-testing"
Collecting mtcnn
  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 24.7 MB/s eta 0:00:00
Requirement already satisfied: opencv-python>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from mtcnn) (4.5.4.60)
Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from mtcnn) (2.11.0)
Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)
Installing collected packages: mtcnn
Successfully installed mtcnn-0.1.1
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Note: you may need to restart the kernel to use updated packages.
image_paths = pd.DataFrame()
img_paths = []
img_labels = []
for file in os.listdir(dataset_path):
    img_paths.append(file)
    img_labels.append(int(file[file.find('_')+1:-4]))

image_paths['image_path']  = img_paths
image_paths['name'] = img_labels

from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils

# take a random sample: 80% of the data for the test set
ml_train, ml_test = train_test_split(image_paths, test_size=0.2, random_state= 123)
ml_train, ml_val = train_test_split(ml_train,test_size=0.2, random_state= 123)
ml_train = ml_train.reset_index().drop("index",1)
ml_test = ml_test.reset_index().drop("index",1)
ml_val = ml_val.reset_index().drop("index",1)



classes_list = list(set(image_paths['name']))

print(len(classes_list))
41
/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  app.launch_new_instance()
/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
# verify resolution of all images is consistent
widths = []
heights = []
files = image_paths.image_path
for file in files:
    path = os.path.join(dataset_path , str(file))
    im = Image.open(path)
    widths.append(im.width)
    heights.append(im.height)

    
width = 80
height = 80
    
pd.DataFrame({'height':heights,'width':widths}).describe()
height	width
count	410.0	410.0
mean	80.0	70.0
std	0.0	0.0
min	80.0	70.0
25%	80.0	70.0
50%	80.0	70.0
75%	80.0	70.0
max	80.0	70.0
im = Image.open(os.path.join(dataset_path, str(ml_train.image_path[0])))
plt.imshow(im)
<matplotlib.image.AxesImage at 0x7973ba3b1b90>

detector = MTCNN()
image = cv2.imread(dataset_path +"/" + str(ml_train.image_path[0]))
result = detector.detect_faces(image)

bounding_box = result[0]['box']
keypoints = result[0]['keypoints']


fig,ax = plt.subplots(1)
ax.imshow(image)

rect = patches.Rectangle(bounding_box[0:2],bounding_box[2],bounding_box[3],linewidth=1,edgecolor='r',facecolor='none')

ax.add_patch(rect)

for key in keypoints:
    rect_key = patches.Rectangle(keypoints[key],1,1,linewidth=10,edgecolor='r',facecolor='none')
    ax.add_patch(rect_key)

plt.show()
1/1 [==============================] - 10s 10s/step
1/1 [==============================] - 0s 173ms/step
1/1 [==============================] - 0s 107ms/step
1/1 [==============================] - 0s 128ms/step
1/1 [==============================] - 0s 219ms/step
1/1 [==============================] - 0s 224ms/step

# initialize sequential network
from keras.models import Sequential
# include convolutional layers
from keras.layers import Conv2D, Dropout
# Pooling layers
from keras.layers import MaxPooling2D

# flatten layers into single vector
from keras.layers import Flatten
from keras.layers import Dense
# define a custom function to move images to a new train/test/val directory

def directory_mover(data,dir_name):
    co = 0
    for image in data.image_path:
        # create top directory
        if not os.path.exists(os.path.join('/kaggle/working/',dir_name)):
            shutil.os.mkdir(os.path.join('/kaggle/working/',dir_name))
        
        data_type = data[data['image_path'] == image]['name']
        data_type = str(list(data_type)[0])
        if not os.path.exists(os.path.join('/kaggle/working/',dir_name,data_type)):
            shutil.os.mkdir(os.path.join('/kaggle/working/',dir_name,data_type))
        path_from = os.path.join(dataset_path,image)
        path_to = os.path.join('/kaggle/working/',dir_name,data_type)
        # print(path_to)
        shutil.copy(path_from, path_to)
        # print('Moved {} to {}'.format(image,path_to))
        co += 1
        
    print('Moved {} images to {} folder.'.format(co,dir_name))
! rm -rf /kaggle/working/*
# move images:
directory_mover(ml_train,"ml_train/")
directory_mover(ml_val,"ml_val/")
directory_mover(ml_test,"ml_test/")
Moved 262 images to ml_train/ folder.
Moved 66 images to ml_val/ folder.
Moved 82 images to ml_test/ folder.
classes_list = [str(x) for x in classes_list]

train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = True)

test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)

ml_training_set = train_datagen.flow_from_directory('/kaggle/working/ml_train/',
                                                 target_size = (70, 80),
                                                 batch_size = 32,
                                                 class_mode = 'sparse',
                                                 classes = classes_list)

ml_val_set = test_datagen.flow_from_directory('/kaggle/working/ml_val/',
                                            target_size = (70, 80),
                                            batch_size = 32,
                                            class_mode = 'sparse',
                                            classes = classes_list)
ml_test_set = test_datagen.flow_from_directory('/kaggle/working/ml_test/',
                                            target_size = (70, 80),
                                            batch_size = 32,
                                            class_mode = 'sparse',
                                            classes = classes_list)
Found 262 images belonging to 41 classes.
Found 66 images belonging to 41 classes.
Found 82 images belonging to 41 classes.
# use sequential classifier - standard CNN implementation with straightforward single input
CNN = Sequential()
# We then add layers of complexity to this classifier. The first layer we add is a 2D convolutional layer (as 
# explained above); we pass over the image with a 3x3 window and expect 250*250 pixel input.
# The activation function to introduce non-linearity  is 'relu': Rectified Linear Units, a simple activation function 
# with low computational speeds. One potential downside is that ReLU can lead to "dying neurons", where a neuron is 
# attributed zero influence on classification and gets stuck in this state; we can see output where many neurons have 
# zero influence on the model. If this behaviour manifested in further analysis, an alternate activation function e.g. 
# 'leaky ReLU' would be worth exploring as an alternative
CNN.add(Conv2D(32, (3, 3), input_shape = (70, 80, 3), activation = 'relu'))

# We now add the pooling layer to reduce the dimension
CNN.add(MaxPooling2D(pool_size = (2, 2)))

CNN.add(Conv2D(64, (3, 3), activation = 'relu'))

CNN.add(MaxPooling2D(pool_size = (2, 2)))

# The next step is to flatten the data, reducing the feature maps to a 1D array
CNN.add(Flatten())

# We then add a fully connected layer - traditional Multi Layer Perceptron
CNN.add(Dense(units = 128, activation = 'relu'))

# as we are just training on 'Bush' vs 'non-Bush', we only need to add one classification unit
CNN.add(Dropout(0.5))

CNN.add(Dense(units = len(classes_list), activation='softmax'))

# We are now ready to compile the model. It is possible, and advisable, to introduce more layers to the network, but
# as this model is exploratory we are keeping things straightforward for now (this would change in future iterations)
CNN.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

CNN_history = CNN.fit(ml_training_set,
                      # set steps per epoch equal to the number of training images
                      steps_per_epoch = 200,
                      # there is a six hour runtime limit on Kaggle Kernels, restricting the maximum epoch number
                      epochs = 10,
                      use_multiprocessing = True,
                      validation_data = ml_val_set,
                      validation_steps = 5
                     )
Epoch 1/10
200/200 [==============================] - 27s 112ms/step - loss: 3.1179 - accuracy: 0.1672 - val_loss: 1.8118 - val_accuracy: 0.4462
Epoch 2/10
200/200 [==============================] - 23s 112ms/step - loss: 1.4720 - accuracy: 0.5455 - val_loss: 0.7190 - val_accuracy: 0.8615
Epoch 3/10
200/200 [==============================] - 23s 113ms/step - loss: 0.9360 - accuracy: 0.6944 - val_loss: 0.4961 - val_accuracy: 0.8462
Epoch 4/10
200/200 [==============================] - 17s 87ms/step - loss: 0.7168 - accuracy: 0.7596 - val_loss: 0.2792 - val_accuracy: 0.9231
Epoch 5/10
200/200 [==============================] - 18s 88ms/step - loss: 0.6139 - accuracy: 0.7872 - val_loss: 0.2415 - val_accuracy: 0.9385
Epoch 6/10
200/200 [==============================] - 17s 86ms/step - loss: 0.5278 - accuracy: 0.8111 - val_loss: 0.2492 - val_accuracy: 0.9231
Epoch 7/10
200/200 [==============================] - 18s 88ms/step - loss: 0.4733 - accuracy: 0.8312 - val_loss: 0.1699 - val_accuracy: 0.9538
Epoch 8/10
200/200 [==============================] - 17s 86ms/step - loss: 0.4486 - accuracy: 0.8379 - val_loss: 0.1556 - val_accuracy: 0.9385
Epoch 9/10
200/200 [==============================] - 17s 86ms/step - loss: 0.4144 - accuracy: 0.8490 - val_loss: 0.1363 - val_accuracy: 0.9462
Epoch 10/10
200/200 [==============================] - 23s 113ms/step - loss: 0.4020 - accuracy: 0.8524 - val_loss: 0.1107 - val_accuracy: 0.9692
test_loss, test_acc = CNN.evaluate(ml_test_set)
print('Test accuracy:', test_acc)
3/3 [==============================] - 0s 50ms/step - loss: 0.2595 - accuracy: 0.9390
Test accuracy: 0.9390243887901306
CNN.save('/kaggle/working/face_recognition_olr.h5')
plt.plot(CNN_history.history['accuracy'])
plt.plot(CNN_history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(CNN_history.history['loss'])
plt.plot(CNN_history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()


if "ml_train" in os.listdir("./"):
    shutil.rmtree("./ml_train")
if "ml_val" in os.listdir("./"):
    shutil.rmtree("./ml_val")
if "ml_test" in os.listdir("./"):
    shutil.rmtree("./ml_test")
import numpy as np
from sklearn.datasets import fetch_olivetti_faces
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt


data = fetch_olivetti_faces()
X = data.data
y = data.target


fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(8, 4))
for i, ax in enumerate(axes.flat):
    ax.imshow(X[i].reshape(64, 64), cmap='gray')
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_title("Image {}".format(i+1))


pca = PCA(n_components=50)
X_pca = pca.fit_transform(X)


plt.figure()
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance')
plt.show()
downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /root/scikit_learn_data


import numpy as np
from sklearn.datasets import fetch_olivetti_faces
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


data = fetch_olivetti_faces()
X = data.data
y = data.target


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


pca = PCA(n_components=50)
X_train_pca = pca.fit_transform(X_train)


svm = SVC(kernel='linear', C=0.9)
svm.fit(X_train_pca, y_train)

X_test_pca = pca.transform(X_test)

y_pred = svm.predict(X_test_pca)


accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: {:.2f}%".format(accuracy * 100))
Accuracy: 97.50%
import numpy as np
from sklearn.datasets import fetch_olivetti_faces
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
import matplotlib.pyplot as plt


data = fetch_olivetti_faces()
X = data.data
y = data.target


fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(8, 4))
for i, ax in enumerate(axes.flat):
    ax.imshow(X[i].reshape(64, 64), cmap='gray')
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_title("Image {}".format(i+1))


lda = LinearDiscriminantAnalysis(n_components=39)
X_lda = lda.fit_transform(X, y)


fig, axes = plt.subplots(nrows=3, ncols=13, figsize=(16, 6))
for i, ax in enumerate(axes.flat):
    if i < 39:
        ax.imshow(lda.scalings_[:, i].reshape(64, 64), cmap='gray')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title("Eigenface {}".format(i+1))
    else:
        ax.axis('off')
plt.show()


import numpy as np
from sklearn.datasets import fetch_olivetti_faces
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

data = fetch_olivetti_faces()
X = data.data
y = data.target


lda = LinearDiscriminantAnalysis(n_components=39)
X_lda = lda.fit_transform(X, y)

clf = KNeighborsClassifier(n_neighbors=32)
scores = cross_val_score(clf, X_lda, y, cv=10)

print("Accuracy: {:.2f} (+/- {:.2f})".format(scores.mean(), scores.std() * 2))
Accuracy: 0.85 (+/- 0.07)
import numpy as np
from sklearn.datasets import fetch_olivetti_faces
from sklearn.decomposition import PCA


data = fetch_olivetti_faces()
X = data.data
y = data.target


pca = PCA(n_components=100)
X_pca = pca.fit_transform(X)

import matplotlib.pyplot as plt
fig, axes = plt.subplots(2, 5, figsize=(10, 4),
                         subplot_kw={'xticks':[], 'yticks':[]},
                         gridspec_kw=dict(hspace=0.1, wspace=0.1))

for i, ax in enumerate(axes.flat):
    ax.imshow(pca.components_[i].reshape(64, 64), cmap='gray')
    ax.set_title("Eigenface {}".format(i+1))

plt.show()

import numpy as np
from sklearn.datasets import fetch_olivetti_faces
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score


data = fetch_olivetti_faces()
X = data.data
y = data.target


pca = PCA(n_components=200)
X_pca = pca.fit_transform(X)


clf = KNeighborsClassifier(n_neighbors=1)
scores = cross_val_score(clf, X_pca, y, cv=10)


print("Accuracy: {:.2f} (+/- {:.2f})".format(scores.mean(), scores.std() * 2))
Accuracy: 0.96 (+/- 0.06)
import cv2
from sklearn.datasets import fetch_olivetti_faces


data = fetch_olivetti_faces()
X = data.images
y = data.target

face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')


for i in range(len(X)):
    img = X[i]
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    
 
    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    
    cv2.imshow('image', img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
---------------------------------------------------------------------------
error                                     Traceback (most recent call last)
/tmp/ipykernel_23/1287586291.py in <module>
     12 for i in range(len(X)):
     13     img = X[i]
---> 14     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
     15     faces = face_cascade.detectMultiScale(gray, 1.3, 5)
     16 

error: OpenCV(4.5.4) /tmp/pip-req-build-jpmv6t9_/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'
> Invalid number of channels in input image:
>     'VScn::contains(scn)'
> where
>     'scn' is 1
